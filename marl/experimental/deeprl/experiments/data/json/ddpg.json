{"__doc__":"config for DDPG on the spread particles environment",
  "agent_density": 4,
  "batch_size":512,
  "buff_seq_length":10,
  "buffer_size":100000,
  "critic_lr":0.005,
  "env_name":"multiagent",
  "eps_decay_slope":2,
  "eps_num_annealings":1,
  "epsilon":0.99,
  "exploration":"marl.experimental.deeprl.exploration.exploration_ou.ExplorationOu",
  "gamma":0.9,
  "hidden_sizes":[128,64,32,32],
  "independent_policy":"marl.experimental.deeprl.policies.ddpg_policy_batched.DDPGPolicyBatched",
  "learning_period":100,
  "lr":0.001,
  "mu":0,
  "network":"marl.experimental.deeprl.policies.networks.SimpleFF",
  "num_agents":4,
  "num_landmarks":4,
  "num_logs":1000,
  "num_perceived_agents":3,
  "num_perceived_landmarks":4,
  "num_learning_iterations":10,
  "num_serializations":10,
  "num_steps":1000000,
  "output_activation":"tanh",
  "output_rescale":null,
  "policy":"marl.experimental.deeprl.policies.independent_policies.IndependentPolicies",
  "render":false,
  "rollout_length":100,
  "scenario_name":"custom/custom_spread",
  "show_agent_velocities":true,
  "sigma":0.55,
  "sleep":0.00,
  "tau":0.01,
  "theta":0.25}